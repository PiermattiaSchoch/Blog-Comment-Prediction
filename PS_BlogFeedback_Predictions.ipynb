{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOG COMMENT PREDICTIONS\n",
    "\n",
    "\n",
    "In this assignment you will try to predict the number of comments that a blog post receives based on features of the post. You  will get the data from the [UCI Machine Learning Archive](https://archive.ics.uci.edu/ml/index.php) here: <https://archive.ics.uci.edu/ml/datasets/BlogFeedback>. The data were originally used in a paper by [Krisztian Buza](http://www.cs.bme.hu/~buza/) (2014): Feedback Prediction for Blogs. In Data Analysis, Machine Learning and Knowledge Discovery (pp. 145-152), available at <http://www.cs.bme.hu/~buza/pdfs/gfkl2012_blogs.pdf>.\n",
    "\n",
    "You will use at least *three* different Machine Learning methods, reporting on the results of each one of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "The rows in training set are 52397\n",
      "The rows in test set are 7624\n",
      "The columns in training set are 281\n",
      "The columns in test set are 281\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "# Import the training set \n",
    "train = spark\\\n",
    "          .read\\\n",
    "          .option(\"inferSchema\", \"true\")\\\n",
    "          .option(\"header\", \"false\")\\\n",
    "          .csv(\"BlogFeedback/Train\") \n",
    "\n",
    "# Import the test set \n",
    "test = spark\\\n",
    "          .read\\\n",
    "          .option(\"inferSchema\", \"true\")\\\n",
    "          .option(\"header\", \"false\")\\\n",
    "          .csv(\"BlogFeedback/Test\") \n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"The rows in training set are\",train.count())\n",
    "print(\"The rows in test set are\",test.count())\n",
    "print(\"The columns in training set are\", len(train.columns))\n",
    "print(\"The columns in test set are\", len(test.columns))\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Printing the schema of the dataset, it is possible to see that all variables are stored as \"double\" type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[_c0: double, _c1: double, _c2: double, _c3: double, _c4: double, _c5: double, _c6: double, _c7: double, _c8: double, _c9: double, _c10: double, _c11: double, _c12: double, _c13: double, _c14: double, _c15: double, _c16: double, _c17: double, _c18: double, _c19: double, _c20: double, _c21: double, _c22: double, _c23: double, _c24: double, _c25: double, _c26: double, _c27: double, _c28: double, _c29: double, _c30: double, _c31: double, _c32: double, _c33: double, _c34: double, _c35: double, _c36: double, _c37: double, _c38: double, _c39: double, _c40: double, _c41: double, _c42: double, _c43: double, _c44: double, _c45: double, _c46: double, _c47: double, _c48: double, _c49: double, _c50: double, _c51: double, _c52: double, _c53: double, _c54: double, _c55: double, _c56: double, _c57: double, _c58: double, _c59: double, _c60: double, _c61: double, _c62: double, _c63: double, _c64: double, _c65: double, _c66: double, _c67: double, _c68: double, _c69: double, _c70: double, _c71: double, _c72: double, _c73: double, _c74: double, _c75: double, _c76: double, _c77: double, _c78: double, _c79: double, _c80: double, _c81: double, _c82: double, _c83: double, _c84: double, _c85: double, _c86: double, _c87: double, _c88: double, _c89: double, _c90: double, _c91: double, _c92: double, _c93: double, _c94: double, _c95: double, _c96: double, _c97: double, _c98: double, _c99: double, _c100: double, _c101: double, _c102: double, _c103: double, _c104: double, _c105: double, _c106: double, _c107: double, _c108: double, _c109: double, _c110: double, _c111: double, _c112: double, _c113: double, _c114: double, _c115: double, _c116: double, _c117: double, _c118: double, _c119: double, _c120: double, _c121: double, _c122: double, _c123: double, _c124: double, _c125: double, _c126: double, _c127: double, _c128: double, _c129: double, _c130: double, _c131: double, _c132: double, _c133: double, _c134: double, _c135: double, _c136: double, _c137: double, _c138: double, _c139: double, _c140: double, _c141: double, _c142: double, _c143: double, _c144: double, _c145: double, _c146: double, _c147: double, _c148: double, _c149: double, _c150: double, _c151: double, _c152: double, _c153: double, _c154: double, _c155: double, _c156: double, _c157: double, _c158: double, _c159: double, _c160: double, _c161: double, _c162: double, _c163: double, _c164: double, _c165: double, _c166: double, _c167: double, _c168: double, _c169: double, _c170: double, _c171: double, _c172: double, _c173: double, _c174: double, _c175: double, _c176: double, _c177: double, _c178: double, _c179: double, _c180: double, _c181: double, _c182: double, _c183: double, _c184: double, _c185: double, _c186: double, _c187: double, _c188: double, _c189: double, _c190: double, _c191: double, _c192: double, _c193: double, _c194: double, _c195: double, _c196: double, _c197: double, _c198: double, _c199: double, _c200: double, _c201: double, _c202: double, _c203: double, _c204: double, _c205: double, _c206: double, _c207: double, _c208: double, _c209: double, _c210: double, _c211: double, _c212: double, _c213: double, _c214: double, _c215: double, _c216: double, _c217: double, _c218: double, _c219: double, _c220: double, _c221: double, _c222: double, _c223: double, _c224: double, _c225: double, _c226: double, _c227: double, _c228: double, _c229: double, _c230: double, _c231: double, _c232: double, _c233: double, _c234: double, _c235: double, _c236: double, _c237: double, _c238: double, _c239: double, _c240: double, _c241: double, _c242: double, _c243: double, _c244: double, _c245: double, _c246: double, _c247: double, _c248: double, _c249: double, _c250: double, _c251: double, _c252: double, _c253: double, _c254: double, _c255: double, _c256: double, _c257: double, _c258: double, _c259: double, _c260: double, _c261: double, _c262: double, _c263: double, _c264: double, _c265: double, _c266: double, _c267: double, _c268: double, _c269: double, _c270: double, _c271: double, _c272: double, _c273: double, _c274: double, _c275: double, _c276: double, _c277: double, _c278: double, _c279: double, _c280: double]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the schema \n",
    "train.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's transform into pandas dataframe to visualize better the datasets. \n",
    "\n",
    "  --> From the chunck below it turns out that we need to standardize some variables \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1    2      3     4         5         6    7      8    9    \\\n",
       "0  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "1  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "2  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "3  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "4  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "\n",
       "   ...  271  272  273  274  275  276  277  278  279   280  \n",
       "0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  \n",
       "1  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  \n",
       "4  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  27.0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52392</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.556349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52393</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.556349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5          6    7     8    9    ...  271  \\\n",
       "52392  33.0  0.0  33.0  33.0  33.0  11.0  15.556349  0.0  33.0  0.0  ...  0.0   \n",
       "52393  33.0  0.0  33.0  33.0  33.0  11.0  15.556349  0.0  33.0  0.0  ...  0.0   \n",
       "52394   0.0  0.0   0.0   0.0   0.0   0.0   0.000000  0.0   0.0  0.0  ...  0.0   \n",
       "52395   0.0  0.0   0.0   0.0   0.0   0.0   0.000000  0.0   0.0  0.0  ...  0.0   \n",
       "52396   0.0  0.0   0.0   0.0   0.0   0.0   0.000000  0.0   0.0  0.0  ...  0.0   \n",
       "\n",
       "       272  273  274  275  276  277  278  279  280  \n",
       "52392  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "52393  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "52394  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "52395  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "52396  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Let's give a look at some useful statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.0</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "      <td>52397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.444167</td>\n",
       "      <td>46.806717</td>\n",
       "      <td>0.358914</td>\n",
       "      <td>339.853102</td>\n",
       "      <td>24.681661</td>\n",
       "      <td>15.214611</td>\n",
       "      <td>27.959159</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>258.666030</td>\n",
       "      <td>5.829151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171327</td>\n",
       "      <td>0.162242</td>\n",
       "      <td>0.154455</td>\n",
       "      <td>0.096151</td>\n",
       "      <td>0.088917</td>\n",
       "      <td>0.119167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.242094</td>\n",
       "      <td>0.769505</td>\n",
       "      <td>6.764719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79.121821</td>\n",
       "      <td>62.359996</td>\n",
       "      <td>6.840717</td>\n",
       "      <td>441.430109</td>\n",
       "      <td>69.598976</td>\n",
       "      <td>32.251189</td>\n",
       "      <td>38.584013</td>\n",
       "      <td>0.131903</td>\n",
       "      <td>321.348052</td>\n",
       "      <td>23.768317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376798</td>\n",
       "      <td>0.368676</td>\n",
       "      <td>0.361388</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.284627</td>\n",
       "      <td>1.438194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.497979</td>\n",
       "      <td>20.338052</td>\n",
       "      <td>37.706565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.285714</td>\n",
       "      <td>5.214318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>3.075076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.630660</td>\n",
       "      <td>19.353120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.150685</td>\n",
       "      <td>11.051215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.304670</td>\n",
       "      <td>77.442830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.998589</td>\n",
       "      <td>45.701206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1122.666600</td>\n",
       "      <td>559.432600</td>\n",
       "      <td>726.000000</td>\n",
       "      <td>2044.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>442.666660</td>\n",
       "      <td>359.530060</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1778.000000</td>\n",
       "      <td>1778.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  52397.000000  52397.000000  52397.000000  52397.000000  52397.000000   \n",
       "mean      39.444167     46.806717      0.358914    339.853102     24.681661   \n",
       "std       79.121821     62.359996      6.840717    441.430109     69.598976   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.285714      5.214318      0.000000     29.000000      0.000000   \n",
       "50%       10.630660     19.353120      0.000000    162.000000      4.000000   \n",
       "75%       40.304670     77.442830      0.000000    478.000000     15.000000   \n",
       "max     1122.666600    559.432600    726.000000   2044.000000   1314.000000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  52397.000000  52397.000000  52397.000000  52397.000000  52397.000000   \n",
       "mean      15.214611     27.959159      0.002748    258.666030      5.829151   \n",
       "std       32.251189     38.584013      0.131903    321.348052     23.768317   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.891566      3.075076      0.000000     22.000000      0.000000   \n",
       "50%        4.150685     11.051215      0.000000    121.000000      1.000000   \n",
       "75%       15.998589     45.701206      0.000000    387.000000      2.000000   \n",
       "max      442.666660    359.530060     14.000000   1424.000000    588.000000   \n",
       "\n",
       "       ...           271           272           273           274  \\\n",
       "count  ...  52397.000000  52397.000000  52397.000000  52397.000000   \n",
       "mean   ...      0.171327      0.162242      0.154455      0.096151   \n",
       "std    ...      0.376798      0.368676      0.361388      0.294800   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                275           276      277           278           279  \\\n",
       "count  52397.000000  52397.000000  52397.0  52397.000000  52397.000000   \n",
       "mean       0.088917      0.119167      0.0      1.242094      0.769505   \n",
       "std        0.284627      1.438194      0.0     27.497979     20.338052   \n",
       "min        0.000000      0.000000      0.0      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.0      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.0      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.0      0.000000      0.000000   \n",
       "max        1.000000    136.000000      0.0   1778.000000   1778.000000   \n",
       "\n",
       "                280  \n",
       "count  52397.000000  \n",
       "mean       6.764719  \n",
       "std       37.706565  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max     1424.000000  \n",
       "\n",
       "[8 rows x 281 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "TEST DATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.630660</td>\n",
       "      <td>17.882992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.018276</td>\n",
       "      <td>10.396790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.435825</td>\n",
       "      <td>75.590485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.998589</td>\n",
       "      <td>44.560870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.733333</td>\n",
       "      <td>3.043390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.526070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.230215</td>\n",
       "      <td>45.970950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.784173</td>\n",
       "      <td>24.209942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.677075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1    2      3     4          5          6    7      8    \\\n",
       "0  10.630660  17.882992  1.0  259.0   5.0   4.018276  10.396790  0.0  235.0   \n",
       "1  43.435825  75.590485  0.0  634.0  20.0  15.998589  44.560870  0.0  473.0   \n",
       "2   1.733333   3.043390  0.0    9.0   0.0   0.733333   1.526070  0.0    5.0   \n",
       "3  27.230215  45.970950  0.0  371.0  14.0  10.784173  24.209942  0.0  228.0   \n",
       "4   4.500000   6.677075  0.0   18.0   0.5   3.000000   4.000000  0.0   10.0   \n",
       "\n",
       "   9    ...  271  272  273  274  275  276  277  278  279  280  \n",
       "0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  \n",
       "1  2.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3  4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  \n",
       "4  0.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's import using pandas to understand better the datasets\n",
    "print(\"TRAIN DATA\")\n",
    "pandas_train = pd.read_csv(\"/Users/admin/Desktop/Spark_Assignment/BlogFeedback/Train/BlogData_train.csv\",\n",
    "                      header = None )\n",
    "display(pandas_train.head(5))\n",
    "display(pandas_train.tail(5))\n",
    "\n",
    "print(\"* Let's give a look at some useful statistics:\")\n",
    "\n",
    "display(pandas_train.describe())\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(\"TEST DATA\")\n",
    "pandas_test = pd.read_csv(\"/Users/admin/Desktop/Spark_Assignment/BlogFeedback/Test/blogData_test-2012.02.01.00_00.csv\",\n",
    "                      header = None )\n",
    "display(pandas_test.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's plot the distribution of the target class :\n",
    "  --> It's extremely zero-inflated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a231336d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the target \n",
    "sns.distplot(pandas_train[280])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booleans and Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total booleans columns are 218\n",
      "The list of numeric columns ['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8', '_c9', '_c10', '_c11', '_c13', '_c14', '_c15', '_c16', '_c17', '_c18', '_c19', '_c20', '_c21', '_c22', '_c23', '_c24', '_c25', '_c26', '_c27', '_c28', '_c29', '_c30', '_c31', '_c33', '_c34', '_c35', '_c36', '_c38', '_c39', '_c40', '_c41', '_c42', '_c43', '_c44', '_c45', '_c46', '_c47', '_c48', '_c49', '_c50', '_c51', '_c52', '_c53', '_c54', '_c55', '_c56', '_c57', '_c58', '_c59', '_c60', '_c61', '_c276', '_c278', '_c279']\n"
     ]
    }
   ],
   "source": [
    "# Check binary columns \n",
    "bb = [col for col in pandas_train if \n",
    "               pandas_train[col].dropna().value_counts().index.isin([0,1]).all()]\n",
    "\n",
    "# Transform in string \n",
    "bool_cols = [str(i) for i in bb]\n",
    "bool_cols\n",
    "\n",
    "# Add a character _c to each item \n",
    "booleans = [\"_c\" + bool_col for bool_col  in bool_cols]\n",
    "print(\"The total booleans columns are\",len(booleans))\n",
    "\n",
    "# Take a list of the total number of column s\n",
    "total_columns = train.columns\n",
    "\n",
    "\n",
    "def diff(first, second):\n",
    "        second = set(second)\n",
    "        return [item for item in first if item not in second]\n",
    "    \n",
    "numeric = diff(total_columns, booleans)\n",
    "\n",
    "# Remove the target column from the list\n",
    "del numeric[-1]\n",
    "print(\"The list of numeric columns\", numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vector Assembler numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take label col \n",
    "label = train.columns[-1]\n",
    "\n",
    "# Create assembler num\n",
    "vec_assembler_num = VectorAssembler(inputCols=numeric, outputCol=\"features_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `StandardScaler` \n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "standardScaler = StandardScaler(inputCol= 'features_num', outputCol=\"features_scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vector Assembler  booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create assembler bool\n",
    "vec_assembler_bool = VectorAssembler(inputCols=booleans, outputCol=\"features_bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_total = VectorAssembler()\\\n",
    "                     .setInputCols([\"features_scaled\",\"features_bool\"])\\\n",
    "                     .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "transformation_pipeline = Pipeline()\\\n",
    "                                  .setStages([vec_assembler_num,\n",
    "                                              standardScaler,\n",
    "                                              vec_assembler_bool,\n",
    "                                              vec_total])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit and Transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: double, _c1: double, _c2: double, _c3: double, _c4: double, _c5: double, _c6: double, _c7: double, _c8: double, _c9: double, _c10: double, _c11: double, _c12: double, _c13: double, _c14: double, _c15: double, _c16: double, _c17: double, _c18: double, _c19: double, _c20: double, _c21: double, _c22: double, _c23: double, _c24: double, _c25: double, _c26: double, _c27: double, _c28: double, _c29: double, _c30: double, _c31: double, _c32: double, _c33: double, _c34: double, _c35: double, _c36: double, _c37: double, _c38: double, _c39: double, _c40: double, _c41: double, _c42: double, _c43: double, _c44: double, _c45: double, _c46: double, _c47: double, _c48: double, _c49: double, _c50: double, _c51: double, _c52: double, _c53: double, _c54: double, _c55: double, _c56: double, _c57: double, _c58: double, _c59: double, _c60: double, _c61: double, _c62: double, _c63: double, _c64: double, _c65: double, _c66: double, _c67: double, _c68: double, _c69: double, _c70: double, _c71: double, _c72: double, _c73: double, _c74: double, _c75: double, _c76: double, _c77: double, _c78: double, _c79: double, _c80: double, _c81: double, _c82: double, _c83: double, _c84: double, _c85: double, _c86: double, _c87: double, _c88: double, _c89: double, _c90: double, _c91: double, _c92: double, _c93: double, _c94: double, _c95: double, _c96: double, _c97: double, _c98: double, _c99: double, _c100: double, _c101: double, _c102: double, _c103: double, _c104: double, _c105: double, _c106: double, _c107: double, _c108: double, _c109: double, _c110: double, _c111: double, _c112: double, _c113: double, _c114: double, _c115: double, _c116: double, _c117: double, _c118: double, _c119: double, _c120: double, _c121: double, _c122: double, _c123: double, _c124: double, _c125: double, _c126: double, _c127: double, _c128: double, _c129: double, _c130: double, _c131: double, _c132: double, _c133: double, _c134: double, _c135: double, _c136: double, _c137: double, _c138: double, _c139: double, _c140: double, _c141: double, _c142: double, _c143: double, _c144: double, _c145: double, _c146: double, _c147: double, _c148: double, _c149: double, _c150: double, _c151: double, _c152: double, _c153: double, _c154: double, _c155: double, _c156: double, _c157: double, _c158: double, _c159: double, _c160: double, _c161: double, _c162: double, _c163: double, _c164: double, _c165: double, _c166: double, _c167: double, _c168: double, _c169: double, _c170: double, _c171: double, _c172: double, _c173: double, _c174: double, _c175: double, _c176: double, _c177: double, _c178: double, _c179: double, _c180: double, _c181: double, _c182: double, _c183: double, _c184: double, _c185: double, _c186: double, _c187: double, _c188: double, _c189: double, _c190: double, _c191: double, _c192: double, _c193: double, _c194: double, _c195: double, _c196: double, _c197: double, _c198: double, _c199: double, _c200: double, _c201: double, _c202: double, _c203: double, _c204: double, _c205: double, _c206: double, _c207: double, _c208: double, _c209: double, _c210: double, _c211: double, _c212: double, _c213: double, _c214: double, _c215: double, _c216: double, _c217: double, _c218: double, _c219: double, _c220: double, _c221: double, _c222: double, _c223: double, _c224: double, _c225: double, _c226: double, _c227: double, _c228: double, _c229: double, _c230: double, _c231: double, _c232: double, _c233: double, _c234: double, _c235: double, _c236: double, _c237: double, _c238: double, _c239: double, _c240: double, _c241: double, _c242: double, _c243: double, _c244: double, _c245: double, _c246: double, _c247: double, _c248: double, _c249: double, _c250: double, _c251: double, _c252: double, _c253: double, _c254: double, _c255: double, _c256: double, _c257: double, _c258: double, _c259: double, _c260: double, _c261: double, _c262: double, _c263: double, _c264: double, _c265: double, _c266: double, _c267: double, _c268: double, _c269: double, _c270: double, _c271: double, _c272: double, _c273: double, _c274: double, _c275: double, _c276: double, _c277: double, _c278: double, _c279: double, _c280: double, features_num: vector, features_scaled: vector, features_bool: vector, features: vector]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the pipeline to training data\n",
    "fitted_pipeline = transformation_pipeline.fit(train)\n",
    "\n",
    "# Now that is fitted it's possible to use it to transform the training data\n",
    "transformed_training = fitted_pipeline.transform(train)\n",
    "\n",
    "# Optimization:\n",
    "# I don't want tha pyspark redo the previous steps again and again\n",
    "# so i cache the data in the memory so the output will be used directly\n",
    "transformed_training.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: double, _c1: double, _c2: double, _c3: double, _c4: double, _c5: double, _c6: double, _c7: double, _c8: double, _c9: double, _c10: double, _c11: double, _c12: double, _c13: double, _c14: double, _c15: double, _c16: double, _c17: double, _c18: double, _c19: double, _c20: double, _c21: double, _c22: double, _c23: double, _c24: double, _c25: double, _c26: double, _c27: double, _c28: double, _c29: double, _c30: double, _c31: double, _c32: double, _c33: double, _c34: double, _c35: double, _c36: double, _c37: double, _c38: double, _c39: double, _c40: double, _c41: double, _c42: double, _c43: double, _c44: double, _c45: double, _c46: double, _c47: double, _c48: double, _c49: double, _c50: double, _c51: double, _c52: double, _c53: double, _c54: double, _c55: double, _c56: double, _c57: double, _c58: double, _c59: double, _c60: double, _c61: double, _c62: double, _c63: double, _c64: double, _c65: double, _c66: double, _c67: double, _c68: double, _c69: double, _c70: double, _c71: double, _c72: double, _c73: double, _c74: double, _c75: double, _c76: double, _c77: double, _c78: double, _c79: double, _c80: double, _c81: double, _c82: double, _c83: double, _c84: double, _c85: double, _c86: double, _c87: double, _c88: double, _c89: double, _c90: double, _c91: double, _c92: double, _c93: double, _c94: double, _c95: double, _c96: double, _c97: double, _c98: double, _c99: double, _c100: double, _c101: double, _c102: double, _c103: double, _c104: double, _c105: double, _c106: double, _c107: double, _c108: double, _c109: double, _c110: double, _c111: double, _c112: double, _c113: double, _c114: double, _c115: double, _c116: double, _c117: double, _c118: double, _c119: double, _c120: double, _c121: double, _c122: double, _c123: double, _c124: double, _c125: double, _c126: double, _c127: double, _c128: double, _c129: double, _c130: double, _c131: double, _c132: double, _c133: double, _c134: double, _c135: double, _c136: double, _c137: double, _c138: double, _c139: double, _c140: double, _c141: double, _c142: double, _c143: double, _c144: double, _c145: double, _c146: double, _c147: double, _c148: double, _c149: double, _c150: double, _c151: double, _c152: double, _c153: double, _c154: double, _c155: double, _c156: double, _c157: double, _c158: double, _c159: double, _c160: double, _c161: double, _c162: double, _c163: double, _c164: double, _c165: double, _c166: double, _c167: double, _c168: double, _c169: double, _c170: double, _c171: double, _c172: double, _c173: double, _c174: double, _c175: double, _c176: double, _c177: double, _c178: double, _c179: double, _c180: double, _c181: double, _c182: double, _c183: double, _c184: double, _c185: double, _c186: double, _c187: double, _c188: double, _c189: double, _c190: double, _c191: double, _c192: double, _c193: double, _c194: double, _c195: double, _c196: double, _c197: double, _c198: double, _c199: double, _c200: double, _c201: double, _c202: double, _c203: double, _c204: double, _c205: double, _c206: double, _c207: double, _c208: double, _c209: double, _c210: double, _c211: double, _c212: double, _c213: double, _c214: double, _c215: double, _c216: double, _c217: double, _c218: double, _c219: double, _c220: double, _c221: double, _c222: double, _c223: double, _c224: double, _c225: double, _c226: double, _c227: double, _c228: double, _c229: double, _c230: double, _c231: double, _c232: double, _c233: double, _c234: double, _c235: double, _c236: double, _c237: double, _c238: double, _c239: double, _c240: double, _c241: double, _c242: double, _c243: double, _c244: double, _c245: double, _c246: double, _c247: double, _c248: double, _c249: double, _c250: double, _c251: double, _c252: double, _c253: double, _c254: double, _c255: double, _c256: double, _c257: double, _c258: double, _c259: double, _c260: double, _c261: double, _c262: double, _c263: double, _c264: double, _c265: double, _c266: double, _c267: double, _c268: double, _c269: double, _c270: double, _c271: double, _c272: double, _c273: double, _c274: double, _c275: double, _c276: double, _c277: double, _c278: double, _c279: double, _c280: double, features_num: vector, features_scaled: vector, features_bool: vector, features: vector]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------\n",
    "# Apply the pipeline to training data\n",
    "fitted_pipeline = transformation_pipeline.fit(test)\n",
    "\n",
    "# Now that is fitted it's possible to use it to transform the training data\n",
    "transformed_test = fitted_pipeline.transform(test)\n",
    "\n",
    "# Optimization\n",
    "transformed_test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It's a good time to take stock of what we have done, and see how the data looks like.\n",
    "  I checked the result with test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|        features_num|     features_scaled|       features_bool|            features|_c280|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|(62,[0,1,3,5,6,8,...|(62,[0,1,3,5,6,8,...|(218,[7,29,41,59,...|(280,[0,1,3,5,6,8...|  0.0|\n",
      "|(62,[0,1,2,3,4,5,...|(62,[0,1,2,3,4,5,...|(218,[7,9,19,41,4...|(280,[0,1,2,3,4,5...|  2.0|\n",
      "|(62,[24,25,27,29,...|(62,[24,25,27,29,...|(218,[208,212],[1...|(280,[24,25,27,29...|  0.0|\n",
      "|(62,[0,1,3,4,5,6,...|(62,[0,1,3,4,5,6,...|(218,[41,83,91,93...|(280,[0,1,3,4,5,6...|  0.0|\n",
      "|(62,[24,26,27,28,...|(62,[24,26,27,28,...|(218,[208,214],[1...|(280,[24,26,27,28...|  0.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Row(_c0=6.004717, _c1=37.53244, _c2=0.0, _c3=347.0, _c4=0.0, _c5=2.6037736, _c6=19.723646, _c7=0.0, _c8=223.0, _c9=0.0, _c10=2.5660377, _c11=19.7262, _c12=0.0, _c13=223.0, _c14=0.0, _c15=4.957547, _c16=28.919914, _c17=0.0, _c18=248.0, _c19=0.0, _c20=0.03773585, _c21=22.372248, _c22=-222.0, _c23=123.0, _c24=0.0, _c25=0.23113208, _c26=0.9849685, _c27=0.0, _c28=8.0, _c29=0.0, _c30=0.094339624, _c31=0.53249687, _c32=0.0, _c33=6.0, _c34=0.0, _c35=0.08490566, _c36=0.52517605, _c37=0.0, _c38=6.0, _c39=0.0, _c40=0.2028302, _c41=0.8694997, _c42=0.0, _c43=7.0, _c44=0.0, _c45=0.009433962, _c46=0.686738, _c47=-5.0, _c48=6.0, _c49=0.0, _c50=2.0, _c51=0.0, _c52=2.0, _c53=2.0, _c54=-2.0, _c55=0.0, _c56=0.0, _c57=0.0, _c58=0.0, _c59=0.0, _c60=41.0, _c61=2954.0, _c62=0.0, _c63=0.0, _c64=0.0, _c65=0.0, _c66=1.0, _c67=0.0, _c68=0.0, _c69=0.0, _c70=0.0, _c71=0.0, _c72=0.0, _c73=0.0, _c74=0.0, _c75=0.0, _c76=0.0, _c77=0.0, _c78=0.0, _c79=0.0, _c80=0.0, _c81=0.0, _c82=0.0, _c83=0.0, _c84=0.0, _c85=0.0, _c86=0.0, _c87=0.0, _c88=1.0, _c89=0.0, _c90=0.0, _c91=0.0, _c92=0.0, _c93=0.0, _c94=0.0, _c95=0.0, _c96=0.0, _c97=0.0, _c98=0.0, _c99=0.0, _c100=1.0, _c101=0.0, _c102=0.0, _c103=0.0, _c104=0.0, _c105=0.0, _c106=0.0, _c107=0.0, _c108=0.0, _c109=0.0, _c110=0.0, _c111=0.0, _c112=0.0, _c113=0.0, _c114=0.0, _c115=0.0, _c116=0.0, _c117=0.0, _c118=1.0, _c119=0.0, _c120=0.0, _c121=0.0, _c122=0.0, _c123=0.0, _c124=0.0, _c125=0.0, _c126=0.0, _c127=0.0, _c128=0.0, _c129=0.0, _c130=0.0, _c131=0.0, _c132=0.0, _c133=0.0, _c134=0.0, _c135=0.0, _c136=0.0, _c137=0.0, _c138=1.0, _c139=0.0, _c140=0.0, _c141=0.0, _c142=1.0, _c143=0.0, _c144=0.0, _c145=0.0, _c146=0.0, _c147=0.0, _c148=0.0, _c149=0.0, _c150=0.0, _c151=0.0, _c152=0.0, _c153=0.0, _c154=0.0, _c155=0.0, _c156=0.0, _c157=0.0, _c158=1.0, _c159=0.0, _c160=0.0, _c161=0.0, _c162=0.0, _c163=0.0, _c164=0.0, _c165=0.0, _c166=0.0, _c167=0.0, _c168=0.0, _c169=0.0, _c170=0.0, _c171=0.0, _c172=0.0, _c173=0.0, _c174=0.0, _c175=0.0, _c176=0.0, _c177=0.0, _c178=0.0, _c179=0.0, _c180=0.0, _c181=0.0, _c182=0.0, _c183=0.0, _c184=0.0, _c185=0.0, _c186=0.0, _c187=0.0, _c188=0.0, _c189=0.0, _c190=0.0, _c191=0.0, _c192=0.0, _c193=0.0, _c194=1.0, _c195=0.0, _c196=1.0, _c197=0.0, _c198=0.0, _c199=0.0, _c200=0.0, _c201=1.0, _c202=0.0, _c203=0.0, _c204=0.0, _c205=0.0, _c206=0.0, _c207=0.0, _c208=0.0, _c209=0.0, _c210=0.0, _c211=0.0, _c212=1.0, _c213=0.0, _c214=0.0, _c215=0.0, _c216=0.0, _c217=0.0, _c218=0.0, _c219=0.0, _c220=0.0, _c221=0.0, _c222=0.0, _c223=0.0, _c224=0.0, _c225=0.0, _c226=0.0, _c227=0.0, _c228=0.0, _c229=1.0, _c230=0.0, _c231=1.0, _c232=0.0, _c233=0.0, _c234=0.0, _c235=0.0, _c236=0.0, _c237=0.0, _c238=0.0, _c239=0.0, _c240=0.0, _c241=0.0, _c242=0.0, _c243=0.0, _c244=0.0, _c245=1.0, _c246=0.0, _c247=1.0, _c248=0.0, _c249=0.0, _c250=0.0, _c251=0.0, _c252=0.0, _c253=0.0, _c254=0.0, _c255=0.0, _c256=0.0, _c257=0.0, _c258=0.0, _c259=0.0, _c260=0.0, _c261=0.0, _c262=0.0, _c263=0.0, _c264=0.0, _c265=0.0, _c266=0.0, _c267=1.0, _c268=0.0, _c269=0.0, _c270=0.0, _c271=0.0, _c272=1.0, _c273=0.0, _c274=0.0, _c275=0.0, _c276=2.0, _c277=0.0, _c278=0.0, _c279=0.0, _c280=0.0, features_num=SparseVector(62, {0: 6.0047, 1: 37.5324, 3: 347.0, 5: 2.6038, 6: 19.7236, 8: 223.0, 10: 2.566, 11: 19.7262, 12: 223.0, 14: 4.9575, 15: 28.9199, 17: 248.0, 19: 0.0377, 20: 22.3722, 21: -222.0, 22: 123.0, 24: 0.2311, 25: 0.985, 27: 8.0, 29: 0.0943, 30: 0.5325, 31: 6.0, 33: 0.0849, 34: 0.5252, 35: 6.0, 37: 0.2028, 38: 0.8695, 40: 7.0, 42: 0.0094, 43: 0.6867, 44: -5.0, 45: 6.0, 47: 2.0, 49: 2.0, 50: 2.0, 51: -2.0, 57: 41.0, 58: 2954.0, 59: 2.0}), features_scaled=SparseVector(62, {0: 0.0788, 1: 0.6942, 3: 0.8889, 5: 0.086, 6: 0.5533, 8: 0.7554, 10: 0.0911, 11: 0.5454, 12: 0.7562, 14: 0.0715, 15: 0.6161, 17: 0.7257, 19: 0.0123, 20: 0.4182, 21: -0.8784, 22: 0.4187, 24: 0.2713, 25: 1.1937, 27: 1.3675, 29: 0.2873, 30: 0.9435, 31: 1.3777, 33: 0.2744, 34: 0.922, 35: 1.3765, 37: 0.2577, 38: 1.0939, 40: 1.2818, 42: 0.4304, 43: 0.8048, 44: -1.3352, 45: 1.3935, 47: 0.0158, 49: 0.0416, 50: 0.0173, 51: -0.0332, 57: 1.9981, 58: 0.7784, 59: 2.046}), features_bool=SparseVector(218, {7: 1.0, 29: 1.0, 41: 1.0, 59: 1.0, 79: 1.0, 83: 1.0, 99: 1.0, 135: 1.0, 137: 1.0, 142: 1.0, 153: 1.0, 170: 1.0, 172: 1.0, 186: 1.0, 188: 1.0, 208: 1.0, 213: 1.0}), features=SparseVector(280, {0: 0.0788, 1: 0.6942, 3: 0.8889, 5: 0.086, 6: 0.5533, 8: 0.7554, 10: 0.0911, 11: 0.5454, 12: 0.7562, 14: 0.0715, 15: 0.6161, 17: 0.7257, 19: 0.0123, 20: 0.4182, 21: -0.8784, 22: 0.4187, 24: 0.2713, 25: 1.1937, 27: 1.3675, 29: 0.2873, 30: 0.9435, 31: 1.3777, 33: 0.2744, 34: 0.922, 35: 1.3765, 37: 0.2577, 38: 1.0939, 40: 1.2818, 42: 0.4304, 43: 0.8048, 44: -1.3352, 45: 1.3935, 47: 0.0158, 49: 0.0416, 50: 0.0173, 51: -0.0332, 57: 1.9981, 58: 0.7784, 59: 2.046, 69: 1.0, 91: 1.0, 103: 1.0, 121: 1.0, 141: 1.0, 145: 1.0, 161: 1.0, 197: 1.0, 199: 1.0, 204: 1.0, 215: 1.0, 232: 1.0, 234: 1.0, 248: 1.0, 250: 1.0, 270: 1.0, 275: 1.0})) \n",
      "\n",
      "Row(_c0=7.7777777, _c1=6.1604075, _c2=1.0, _c3=18.0, _c4=6.0, _c5=3.3333333, _c6=3.681787, _c7=0.0, _c8=13.0, _c9=2.0, _c10=2.7777777, _c11=3.9377878, _c12=0.0, _c13=13.0, _c14=1.0, _c15=6.5555553, _c16=4.85595, _c17=1.0, _c18=13.0, _c19=6.0, _c20=0.5555556, _c21=5.7176356, _c22=-10.0, _c23=13.0, _c24=1.0, _c25=0.0, _c26=0.0, _c27=0.0, _c28=0.0, _c29=0.0, _c30=0.0, _c31=0.0, _c32=0.0, _c33=0.0, _c34=0.0, _c35=0.0, _c36=0.0, _c37=0.0, _c38=0.0, _c39=0.0, _c40=0.0, _c41=0.0, _c42=0.0, _c43=0.0, _c44=0.0, _c45=0.0, _c46=0.0, _c47=0.0, _c48=0.0, _c49=0.0, _c50=1.0, _c51=1.0, _c52=0.0, _c53=1.0, _c54=1.0, _c55=0.0, _c56=0.0, _c57=0.0, _c58=0.0, _c59=0.0, _c60=5.0, _c61=9832.0, _c62=0.0, _c63=0.0, _c64=0.0, _c65=0.0, _c66=1.0, _c67=0.0, _c68=1.0, _c69=0.0, _c70=0.0, _c71=0.0, _c72=0.0, _c73=0.0, _c74=0.0, _c75=0.0, _c76=0.0, _c77=0.0, _c78=1.0, _c79=0.0, _c80=0.0, _c81=0.0, _c82=0.0, _c83=0.0, _c84=0.0, _c85=0.0, _c86=0.0, _c87=0.0, _c88=0.0, _c89=0.0, _c90=0.0, _c91=0.0, _c92=0.0, _c93=0.0, _c94=0.0, _c95=0.0, _c96=0.0, _c97=0.0, _c98=0.0, _c99=0.0, _c100=1.0, _c101=1.0, _c102=0.0, _c103=1.0, _c104=0.0, _c105=0.0, _c106=0.0, _c107=1.0, _c108=0.0, _c109=0.0, _c110=0.0, _c111=0.0, _c112=0.0, _c113=1.0, _c114=0.0, _c115=0.0, _c116=0.0, _c117=0.0, _c118=0.0, _c119=0.0, _c120=0.0, _c121=1.0, _c122=0.0, _c123=0.0, _c124=0.0, _c125=0.0, _c126=0.0, _c127=0.0, _c128=0.0, _c129=0.0, _c130=0.0, _c131=0.0, _c132=0.0, _c133=0.0, _c134=0.0, _c135=0.0, _c136=0.0, _c137=0.0, _c138=0.0, _c139=0.0, _c140=0.0, _c141=0.0, _c142=1.0, _c143=0.0, _c144=0.0, _c145=0.0, _c146=0.0, _c147=0.0, _c148=0.0, _c149=0.0, _c150=1.0, _c151=0.0, _c152=1.0, _c153=0.0, _c154=0.0, _c155=0.0, _c156=0.0, _c157=0.0, _c158=0.0, _c159=0.0, _c160=0.0, _c161=0.0, _c162=0.0, _c163=0.0, _c164=0.0, _c165=0.0, _c166=0.0, _c167=0.0, _c168=0.0, _c169=1.0, _c170=0.0, _c171=0.0, _c172=0.0, _c173=0.0, _c174=0.0, _c175=0.0, _c176=0.0, _c177=0.0, _c178=0.0, _c179=0.0, _c180=0.0, _c181=0.0, _c182=1.0, _c183=1.0, _c184=0.0, _c185=0.0, _c186=0.0, _c187=0.0, _c188=0.0, _c189=0.0, _c190=0.0, _c191=0.0, _c192=0.0, _c193=0.0, _c194=0.0, _c195=0.0, _c196=0.0, _c197=0.0, _c198=0.0, _c199=0.0, _c200=0.0, _c201=1.0, _c202=0.0, _c203=0.0, _c204=0.0, _c205=0.0, _c206=1.0, _c207=0.0, _c208=0.0, _c209=0.0, _c210=0.0, _c211=0.0, _c212=1.0, _c213=0.0, _c214=0.0, _c215=0.0, _c216=0.0, _c217=0.0, _c218=0.0, _c219=0.0, _c220=0.0, _c221=0.0, _c222=0.0, _c223=0.0, _c224=0.0, _c225=1.0, _c226=0.0, _c227=0.0, _c228=0.0, _c229=1.0, _c230=0.0, _c231=1.0, _c232=0.0, _c233=0.0, _c234=0.0, _c235=0.0, _c236=0.0, _c237=0.0, _c238=0.0, _c239=0.0, _c240=0.0, _c241=0.0, _c242=0.0, _c243=0.0, _c244=0.0, _c245=1.0, _c246=0.0, _c247=1.0, _c248=0.0, _c249=0.0, _c250=0.0, _c251=1.0, _c252=0.0, _c253=0.0, _c254=0.0, _c255=0.0, _c256=1.0, _c257=0.0, _c258=0.0, _c259=0.0, _c260=1.0, _c261=0.0, _c262=0.0, _c263=0.0, _c264=0.0, _c265=0.0, _c266=0.0, _c267=1.0, _c268=0.0, _c269=0.0, _c270=0.0, _c271=0.0, _c272=0.0, _c273=1.0, _c274=0.0, _c275=0.0, _c276=0.0, _c277=0.0, _c278=0.0, _c279=0.0, _c280=2.0, features_num=SparseVector(62, {0: 7.7778, 1: 6.1604, 2: 1.0, 3: 18.0, 4: 6.0, 5: 3.3333, 6: 3.6818, 8: 13.0, 9: 2.0, 10: 2.7778, 11: 3.9378, 12: 13.0, 13: 1.0, 14: 6.5556, 15: 4.856, 16: 1.0, 17: 13.0, 18: 6.0, 19: 0.5556, 20: 5.7176, 21: -10.0, 22: 13.0, 23: 1.0, 47: 1.0, 48: 1.0, 50: 1.0, 51: 1.0, 57: 5.0, 58: 9832.0}), features_scaled=SparseVector(62, {0: 0.102, 1: 0.1139, 2: 0.0301, 3: 0.0461, 4: 0.0795, 5: 0.1101, 6: 0.1033, 8: 0.044, 9: 0.0708, 10: 0.0986, 11: 0.1089, 12: 0.0441, 13: 0.0396, 14: 0.0945, 15: 0.1034, 16: 0.0301, 17: 0.038, 18: 0.0844, 19: 0.1811, 20: 0.1069, 21: -0.0396, 22: 0.0443, 23: 0.1629, 47: 0.0079, 48: 0.0199, 50: 0.0086, 51: 0.0166, 57: 0.2437, 58: 2.5909}), features_bool=SparseVector(218, {7: 1.0, 9: 1.0, 19: 1.0, 41: 1.0, 42: 1.0, 44: 1.0, 48: 1.0, 54: 1.0, 62: 1.0, 83: 1.0, 91: 1.0, 93: 1.0, 110: 1.0, 123: 1.0, 124: 1.0, 142: 1.0, 147: 1.0, 153: 1.0, 166: 1.0, 170: 1.0, 172: 1.0, 186: 1.0, 188: 1.0, 192: 1.0, 197: 1.0, 201: 1.0, 208: 1.0, 214: 1.0}), features=SparseVector(280, {0: 0.102, 1: 0.1139, 2: 0.0301, 3: 0.0461, 4: 0.0795, 5: 0.1101, 6: 0.1033, 8: 0.044, 9: 0.0708, 10: 0.0986, 11: 0.1089, 12: 0.0441, 13: 0.0396, 14: 0.0945, 15: 0.1034, 16: 0.0301, 17: 0.038, 18: 0.0844, 19: 0.1811, 20: 0.1069, 21: -0.0396, 22: 0.0443, 23: 0.1629, 47: 0.0079, 48: 0.0199, 50: 0.0086, 51: 0.0166, 57: 0.2437, 58: 2.5909, 69: 1.0, 71: 1.0, 81: 1.0, 103: 1.0, 104: 1.0, 106: 1.0, 110: 1.0, 116: 1.0, 124: 1.0, 145: 1.0, 153: 1.0, 155: 1.0, 172: 1.0, 185: 1.0, 186: 1.0, 204: 1.0, 209: 1.0, 215: 1.0, 228: 1.0, 232: 1.0, 234: 1.0, 248: 1.0, 250: 1.0, 254: 1.0, 259: 1.0, 263: 1.0, 270: 1.0, 276: 1.0})) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check \n",
    "transformed_test.select(\"features_num\",\"features_scaled\",\"features_bool\",\"features\",label).show(5)\n",
    "\n",
    "for line in transformed_test.head(2):\n",
    "    print(line, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking the output it is possible to see that 4 `SparseVector` has been created. \n",
    "\n",
    "  Indeed i set this during the creation of the `Pipeline`. \n",
    "  For the Modelling Phase i will use only the `Features` vector.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GBTRegressor, RandomForestRegressor\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder,TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  ELASTIC NET REGULARIZED  LINEAR REGRESSION\n",
    "\n",
    "   * The predictions generated are negative due to an huge amount of \"0\" in the label column of dataframes.\n",
    "   \n",
    "     --> This suggest that other models should be more appropiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 24.703639943489787\n",
      "MSE: 610.2698264575841\n",
      "R2: 0.3439674912128392\n",
      "MAE: 7.936459821252557\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "lr = (LinearRegression(featuresCol= 'features', labelCol = label, predictionCol='pred_label',\n",
    "                       maxIter=50, regParam=0.3, elasticNetParam= 0.9, fitIntercept = True))\n",
    "# Fit the data to the model\n",
    "lrModel = lr.fit(transformed_training)\n",
    "\n",
    "# Evaluate\n",
    "test_results_lr = lrModel.evaluate(transformed_test)\n",
    "\n",
    "# Predictions\n",
    "predictions_lr = lrModel.transform(transformed_test)\n",
    "\n",
    "print(\"RMSE: {}\".format(test_results_lr.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_results_lr.meanSquaredError))\n",
    "print(\"R2: {}\".format(test_results_lr.r2))\n",
    "print(\"MAE: {}\".format(test_results_lr.meanAbsoluteError))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|         pred_label|_c280|\n",
      "+-------------------+-----+\n",
      "| 0.5238836351307414|  0.0|\n",
      "|  8.019981517866245|  2.0|\n",
      "| -4.100108415061402|  0.0|\n",
      "| 0.5876567408130802|  0.0|\n",
      "|  2.371787252489308|  0.0|\n",
      "|  -4.37594633338781|  0.0|\n",
      "|  9.405787556406342|  4.0|\n",
      "|-1.7885967716086526|  1.0|\n",
      "|  44.49170632056693|  1.0|\n",
      "|  8.912400867968412|  0.0|\n",
      "+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the predictions and the \"known\" correct labels\n",
    "predandlabels = predictions_lr.select(\"pred_label\", label)\n",
    "predandlabels.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TUNING LINEAR REGRESSION\n",
    " \n",
    "   * I tuned the parameters of the elestic net just to play with pyspark MLlib.\n",
    "   \n",
    "     It takes approximately 2-3 mins in a 4core-16gb machine for a minimum improvement (RMSE: 24.70 vs RMSE: 24.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol= 'features', labelCol = label ,maxIter=50)\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.5,0.45,0.40,0.35,0.30,0.25,0.20,0.15,0.10,0.05,0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.1,0.2,0.3,0.4, 0.5,0.6,0.7])\\\n",
    "    .build()\n",
    "\n",
    "# In this case the estimator is simply the linear regression.\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(labelCol=label, predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|_c280|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|(280,[0,1,3,5,6,8...|  0.0|0.43008206982286534|\n",
      "|(280,[0,1,2,3,4,5...|  2.0|  8.070212650989436|\n",
      "|(280,[24,25,27,29...|  0.0| -4.182908125776822|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|0.48983671255666383|\n",
      "|(280,[24,26,27,28...|  0.0| 2.4183083374817036|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|-4.5127598622357015|\n",
      "|(280,[0,1,2,3,4,5...|  4.0|  9.389442003133162|\n",
      "|(280,[0,1,3,5,6,8...|  1.0|-1.8655184529889937|\n",
      "|(280,[47,48,50,51...|  1.0|  43.99156745567804|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|   9.15298537038538|\n",
      "|(280,[0,1,3,5,6,8...|  0.0|  5.164123048248627|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|  5.251309977306188|\n",
      "|(280,[0,1,2,3,4,5...|  0.0|  1.913757086417876|\n",
      "|(280,[0,1,3,5,6,8...|  0.0|-2.5005994246447223|\n",
      "|(280,[47,48,49,50...|  2.0| -29.82576856958338|\n",
      "|(280,[52,53,54,55...|  0.0|-1.1329724517204403|\n",
      "|(280,[52,53,55,56...|  0.0|   3.46235701572886|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|  4.515693865354947|\n",
      "|(280,[0,1,2,3,4,5...|  0.0|   9.29915823009381|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|-3.2626606384126395|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 24.6727\n"
     ]
    }
   ],
   "source": [
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(transformed_training)\n",
    "\n",
    "# Make predictions on test data. model is the model with combination of parameters\n",
    "# that performed best.\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(transformed_test)\n",
    "\n",
    "model.transform(transformed_test)\\\n",
    "                .select(\"features\", label, \"prediction\")\\\n",
    "                .show()\n",
    "# Evaluator\n",
    "evaluator=RegressionEvaluator(labelCol=label, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "# Rmse\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POISSON MODEL \n",
    "\n",
    "   * A limitation of the model is the assumption that the conditional variance = the conditional mean, which may not  always be true. This model is overdispersed (conditional variance > conditional mean), so i will need to use the Negative Binomial model instead.\n",
    "   \n",
    "   * Negative Binomial model is not implemented in MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|_c280|        pred_label|\n",
      "+--------------------+-----+------------------+\n",
      "|(280,[0,1,3,5,6,8...|  0.0| 4.552013312117276|\n",
      "|(280,[0,1,2,3,4,5...|  2.0| 7.648070758090618|\n",
      "|(280,[24,25,27,29...|  0.0| 2.560727874717512|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|5.2596936471047195|\n",
      "|(280,[24,26,27,28...|  0.0| 5.179674482016507|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Poisson Model\n",
    "glr = GeneralizedLinearRegression(family=\"Poisson\", link=\"Log\",\n",
    "                                  featuresCol= 'features', labelCol = label, predictionCol='pred_label',\n",
    "                                  maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "glrModel = glr.fit(transformed_training)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_glr = glrModel.transform(transformed_test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_glr.select(\"features\",label,\"pred_label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 28.4299\n",
      "Mean Absolute Error (MAE) on test data = 8.76682\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_mae = RegressionEvaluator(labelCol= label,\n",
    "                                predictionCol=\"pred_label\",\n",
    "                                metricName= \"mae\")\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol= label,\n",
    "                                predictionCol=\"pred_label\",\n",
    "                                metricName= \"rmse\")\n",
    "\n",
    "rmse_glr = evaluator_rmse.evaluate(predictions_glr)\n",
    "mae_glr  = evaluator_mae.evaluate(predictions_glr)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_glr)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae_glr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.13988136256354256\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate R^2\n",
    "y_true = predictions.select(label).toPandas()\n",
    "y_pred = predictions.select(\"pred_label\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DECISION TREE REGRESSION\n",
    "\n",
    "   *  I choosed not to try to tune the parameter of decision tree model.\n",
    "   *   In the next chunk i will run Random Forest model and try to optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|        prediction|_c280|\n",
      "+------------------+-----+\n",
      "|0.5013598997646915|  0.0|\n",
      "| 2.750554100342535|  2.0|\n",
      "|0.5013598997646915|  0.0|\n",
      "|0.5013598997646915|  0.0|\n",
      "|0.5013598997646915|  0.0|\n",
      "+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 25.5492\n",
      "Mean Squared Error (MSE) on test data = 5.7403\n"
     ]
    }
   ],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol = \"_c280\")\n",
    "# Train model.  This also runs the indexer.\n",
    "dtModel = dt.fit(transformed_training)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_dt = dtModel.transform(transformed_test)\n",
    "\n",
    "#Select example rows to display.\n",
    "predictions_dt.select(\"prediction\", label).show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"_c280\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"_c280\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "rmse_dt = evaluator_rmse.evaluate(predictions_dt)\n",
    "mae_dt = evaluator_mae.evaluate(predictions_dt)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_dt)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mae_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|_c280|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|0.6017666411476418|  0.0|(280,[0,1,3,5,6,8...|\n",
      "|1.9038359937013962|  2.0|(280,[0,1,2,3,4,5...|\n",
      "| 0.523098110815329|  0.0|(280,[24,25,27,29...|\n",
      "|1.3682309204733967|  0.0|(280,[0,1,3,4,5,6...|\n",
      "|0.5755896124270652|  0.0|(280,[24,26,27,28...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 23.1034\n",
      "Mean Squared Error (MSE) on test data = 5.75236\n"
     ]
    }
   ],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol = \"_c280\")\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "rfModel = rf.fit(transformed_training)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_rf = rfModel.transform(transformed_test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_rf.select(\"prediction\", label, \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=label, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=label, predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "rmse_rf = evaluator_rmse.evaluate(predictions_rf)\n",
    "mae_rf = evaluator_mae.evaluate(predictions_rf)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_rf)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mae_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TUNING RANDOM FOREST\n",
    "  \n",
    "   * I SUGGEST NOT RUN THIS CHUNK \n",
    "   \n",
    "   \n",
    "   * The code for tuning the random forest works. However this in not an optimization because it performs worst than the default parameter of the random forest specified before. Indeed i was not able to play with parameter that are considered \"small\" in terms of computation of the algorithm. If bigger search are implemented locally, the system will run out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol = label)\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(rf.numTrees, [1,10]) \\\n",
    "    .addGrid(rf.maxDepth, [2, 10])\\\n",
    "    .build()\n",
    "\n",
    "# In this case the estimator is simply the linear regression.\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "rvs = TrainValidationSplit(estimator=rf,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(labelCol=label, predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|_c280|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|(280,[0,1,3,5,6,8...|  0.0| 0.3423342828299061|\n",
      "|(280,[0,1,2,3,4,5...|  2.0| 2.2173910100017227|\n",
      "|(280,[24,25,27,29...|  0.0|0.04712399434136953|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|  0.548537253756256|\n",
      "|(280,[24,26,27,28...|  0.0|0.12415687006207121|\n",
      "|(280,[0,1,3,4,5,6...|  0.0| 1.3142310599296085|\n",
      "|(280,[0,1,2,3,4,5...|  4.0| 6.1099089175975525|\n",
      "|(280,[0,1,3,5,6,8...|  1.0| 1.2529054612373047|\n",
      "|(280,[47,48,50,51...|  1.0|  41.08724164711184|\n",
      "|(280,[0,1,3,4,5,6...|  0.0| 0.9366943861807062|\n",
      "|(280,[0,1,3,5,6,8...|  0.0|    4.2449326547507|\n",
      "|(280,[0,1,3,4,5,6...|  0.0| 4.4339356683891715|\n",
      "|(280,[0,1,2,3,4,5...|  0.0| 1.2161490465674067|\n",
      "|(280,[0,1,3,5,6,8...|  0.0| 0.2649618382326759|\n",
      "|(280,[47,48,49,50...|  2.0|  1.685446383457189|\n",
      "|(280,[52,53,54,55...|  0.0|0.04712399434136953|\n",
      "|(280,[52,53,55,56...|  0.0|0.08710978582777802|\n",
      "|(280,[0,1,3,4,5,6...|  0.0| 0.8728960203317033|\n",
      "|(280,[0,1,2,3,4,5...|  0.0|  5.230528992225567|\n",
      "|(280,[0,1,3,4,5,6...|  0.0|  3.018844844442564|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 24.1725\n"
     ]
    }
   ],
   "source": [
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = rvs.fit(transformed_training)\n",
    "\n",
    "# Make predictions on test data. model is the model with combination of parameters\n",
    "# that performed best.\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(transformed_test)\n",
    "\n",
    "model.transform(transformed_test)\\\n",
    "                .select(\"features\", label, \"prediction\")\\\n",
    "                .show()\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator( labelCol= \"_c280\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "# Rmse\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GRADIENT-BOOSTED TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          prediction|_c280|            features|\n",
      "+--------------------+-----+--------------------+\n",
      "|0.037826276218454746|  0.0|(280,[0,1,3,5,6,8...|\n",
      "|   6.028552043624663|  2.0|(280,[0,1,2,3,4,5...|\n",
      "|0.037826276218454746|  0.0|(280,[24,25,27,29...|\n",
      "| 0.04919423065831681|  0.0|(280,[0,1,3,4,5,6...|\n",
      "|  -5.172463476532891|  0.0|(280,[24,26,27,28...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 27.4158\n",
      "Mean Squared Error (MSE) on test data = 5.73736\n"
     ]
    }
   ],
   "source": [
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol = \"_c280\", maxIter=10)\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "gbtModel = gbt.fit(transformed_training)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_gbt = gbtModel.transform(transformed_test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions_gbt.select(\"prediction\", label, \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_rmse = RegressionEvaluator( labelCol= \"_c280\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"_c280\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "rmse_gbt = evaluator_rmse.evaluate(predictions_gbt)\n",
    "mae_gbt = evaluator_mae.evaluate(predictions_gbt)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_gbt)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mae_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL COMPARISON "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Let's create a dataframe that store all the results obtained \n",
    " \n",
    "\n",
    " \n",
    " * Mean Absolute Error (MAE) and Root mean squared error (RMSE) are two of the most common metrics used to measure accuracy for continuous variables. \n",
    " \n",
    " \n",
    " * Mean Absolute Error (MAE): MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It’s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n",
    " \n",
    " \n",
    "* RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It’s the square root of the average of squared differences between prediction and actual observation.\n",
    "\n",
    "\n",
    "* Differences: Taking the square root of the average squared errors has some interesting implications for RMSE. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable, while MAE its more robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elasticnet_linear_regression</th>\n",
       "      <th>poisson_regression</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>gradient_boosted_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>24.70364</td>\n",
       "      <td>28.429927</td>\n",
       "      <td>25.549200</td>\n",
       "      <td>23.103402</td>\n",
       "      <td>27.415848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>7.93646</td>\n",
       "      <td>8.766825</td>\n",
       "      <td>5.740302</td>\n",
       "      <td>5.752364</td>\n",
       "      <td>5.737359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      elasticnet_linear_regression  poisson_regression  decision_tree  \\\n",
       "RMSE                      24.70364           28.429927      25.549200   \n",
       "MAE                        7.93646            8.766825       5.740302   \n",
       "\n",
       "      random_forest  gradient_boosted_tree  \n",
       "RMSE      23.103402              27.415848  \n",
       "MAE        5.752364               5.737359  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'elasticnet_linear_regression':[test_results_lr.rootMeanSquaredError,test_results_lr.meanAbsoluteError],\n",
    "    'poisson_regression':[rmse_glr,mae_glr],\n",
    "    'decision_tree':[rmse_dt,mae_dt],\n",
    "    'random_forest':[rmse_rf,mae_rf],\n",
    "    'gradient_boosted_tree':[rmse_gbt, mae_gbt]\n",
    "})\n",
    "\n",
    "\n",
    "df.rename(index={0: 'RMSE', 1: 'MAE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = df.plot.bar(color=[\"SkyBlue\",\"IndianRed\",\"Orange\",\"Yellow\",\"Green\"], \n",
    "                 rot=0,figsize=(15,8))\n",
    "ax.set_xlabel(\"RMSE VS MAE\", size = 20)\n",
    "ax.set_ylabel(\"Value \",size = 20)\n",
    "plt.legend(loc=1, prop={'size': 15})\n",
    "plt.title('MODEL COMPARISON', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ---------> Taking into account both source of errors, **the best model is the random forest with default parameters** <--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "\n",
    "  * In this analysis i used the current models available using DataFrame API available using the library MLlib\n",
    "    https://spark.apache.org/docs/latest/ml-guide.html.\n",
    "    \n",
    "    \n",
    "  * It should be notice that other models are available converting data into RDD. \n",
    "  \n",
    "    Here  -- > (~/spark-2.4.2-bin-hadoop2.7/examples/src/main/python) it is possible to find many built-in models  for classification / regressions problems"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
